---
title: Microbiome composition upon priming in the larvae of *Tribolium castaneum*
author: "Shrey Gandhi; Ana Korsa"
output: 
  html_document:
        keep_md: true
---
## **Project Overview**
Priming response (enhanced survival upon secondary infection) has been demonstrated with different routes (septic and oral) in the red flour beetle *Tribolium castaneum* and shows to have high degree of specificity.  Some studies have pointed out the importance of the hosts natural microbiota, suggesting that priming  might be partially explained by the presence of commensal bacteria in the gut. Using a well established model system for studying host-parasite interaction and insect immunity, red flour beetle *Tribolium castaneum* and enthomopathogenic bacterium *Bacillus thurigiensis* (Bt), we have studied if priming could influence microbiome composition of the beetle larvae. We conducted an experiment using the two established routes of priming in this system: injection with heat-killed Bt and oral via ingestion of filtered sterilized bacterial spore supernatants by beetle larvae, with diverse strains of Bt varying in their ability to induce priming. Microbiota composition was assessed after the priming treatment by deep sequencing of the v1-v2 region of the bacterial 16S rRNA gene.

## **Sequencing Methodology**
For sequencing, variable regions V1 and V2 of the 16S rRNA gene within the DNA samples were amplified using the primer pair 27F-338R in a dual-barcoding approach as per Caporaso et al. 2012. 3.5 Âµl of cDNA was used for amplification and PCR products were verified using the electrophoresis in agarose gel. PCR products were normalized using the SequalPrep Normalization Plate Kit, pooled equimolarly, and sequenced on the Illumina MiSeq v3 2x300bp. Demultiplexing after sequencing was based on 0 mismatches in the barcode sequences.


## **Loading R packages:**
```{r libraries, echo=T, message=FALSE, warning=FALSE, cache=FALSE}
library(rmarkdown)
library(dada2)
library(ggplot2)
library(phyloseq)
library(DECIPHER)
library(phangorn)
library(ape)
library(decontam)
```

## **Pre-processing the reads:**

```{r Pre-processing, echo=T, message=FALSE, warning=FALSE, fig.dim= c(12,8), fig.align= "centre", layout="l-body-outset"}
# Loading the Forward and reverse fastq files for all the samples:
path <- "ngs_data"
fnFs <- sort(list.files(path, pattern="_R1.fastq.gz", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_R2.fastq.gz", full.names = TRUE))
# Extract sample names:
sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1)

# Plotting the quality profiles of the reads of first 10 samples:
temp <- sample.names[1:8]
names(temp) <- basename(fnFs)[1:8]
plotQualityProfile(fnFs[1:8]) + ggtitle("Forward") + facet_wrap(~file, ncol = 4, labeller=as_labeller(temp))
names(temp) <- basename(fnRs)[1:8]
plotQualityProfile(fnRs[1:8]) + ggtitle("Reverse") + facet_wrap(~file, ncol = 4, labeller=as_labeller(temp))

# Trimming the fastq files:
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, trimLeft = c(5,5) , truncLen=c(240,220),
                     maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
                     compress=TRUE, multithread=TRUE)

## Checking quality after trimming the reads:
temp <- sample.names[1:8]
names(temp) <- basename(filtFs)[1:8]
plotQualityProfile(filtFs[1:8]) + ggtitle("Forward") + facet_wrap(~file, ncol = 4, labeller=as_labeller(temp))
names(temp) <- basename(filtRs)[1:8]
plotQualityProfile(filtRs[1:8]) + ggtitle("Reverse") + facet_wrap(~file, ncol = 4, labeller=as_labeller(temp))

# De-replication: 
derepFs <- derepFastq(filtFs)
derepRs <- derepFastq(filtRs)
# Name the derep-class objects by the sample names
names(derepFs) <- sample.names
names(derepRs) <- sample.names

#Learning the error rates:
errF <- learnErrors(filtFs, multithread=TRUE, verbose = F)
errR <- learnErrors(filtRs, multithread=TRUE, verbose = F)
plotErrors(errF, nominalQ=TRUE)
plotErrors(errR, nominalQ=TRUE)
```
```{r clean, message=FALSE, warning=FALSE, cache=FALSE, include=FALSE, paged.print=FALSE}
gc()
```
## **Creating ASV table:**

```{r dada2, echo=T, message=FALSE, warning=FALSE, fig.dim= c(12,8), fig.align= "centre", layout="l-body-outset"}
#Creating dada objects:
dadaFs <- dada(derepFs, err=errF, multithread=TRUE, verbose = F)
dadaRs <- dada(derepRs, err=errR, multithread=TRUE, verbose = F)

# Merge paired reads
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose = F)
# Constructing ASV sequence table
seqtab <- makeSequenceTable(mergers)
# Inspect distribution of sequence lengths:
table(nchar(getSequences(seqtab)))

# Remove chimeras
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=F)
# Chimeras account for 4.1% of the merged sequence reads:
(1- sum(seqtab.nochim)/sum(seqtab)) *100

#Tracking reads through the pipeline:
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
paged_table(as.data.frame(track))
rm(getN,out,filtFs,filtRs,dadaFs,dadaRs,fnFs,fnRs,derepFs,derepRs,errF,errR,mergers,seqtab,temp)

# Assigning taxonomy using Silva database
taxa <- assignTaxonomy(seqtab.nochim, "database/silva 138/silva_nr99_v138_train_set.fa.gz", 
                       multithread=TRUE, verbose = FALSE)
taxa <- addSpecies(taxa, "database/silva 138/silva_species_assignment_v138.fa.gz")

# making a fasta of ASV seqs:
asv_seqs <- colnames(seqtab.nochim)
asv_headers <- vector(dim(seqtab.nochim)[2], mode="character")
asv_fasta <- asv_seqs
for (i in 1:dim(seqtab.nochim)[2]) {
  asv_headers[i] <- paste(">ASV", i, sep="_")
}
asv_fasta <- c(rbind(asv_headers, asv_seqs))

# Making ASV count table:
asv_tab <- t(seqtab.nochim)
row.names(asv_tab) <- sub(">", "", asv_headers)
asv_tab<-as.matrix(asv_tab)

#Making ASV taxanomy table:
asv_tax <- taxa
row.names(asv_tax) <- sub(">", "", asv_headers)
paged_table(as.data.frame(asv_tax))

# DADA2 complete.
```

```{r clean2, message=FALSE, warning=FALSE, cache=FALSE, include=FALSE, paged.print=FALSE}
gc()
```

## **Creating a phyloseq object:**

```{r phyloseq, echo=T, message=FALSE, warning=FALSE, fig.dim= c(12,8), fig.align= "centre", layout="l-body-outset"}
# Reading the table with samples and treatments
sample_table <- as.data.frame(read.csv("Sample_table.csv",sep=";" ))
sample_table <- sample_table[1:90,c(1,4:11)]
rownames(sample_table) <- sample_table$Samples
paged_table(sample_table)

count_phy <- otu_table(asv_tab, taxa_are_rows=T)
sample_table_phy <- sample_data(sample_table)
tax_tab_phy<-tax_table(asv_tax)

# Creating Phylogenetic Tree of ASVs:
# Aligning the sequences:
seqs <-(grep(pattern = ">ASV", asv_fasta,invert = T,value = T))
names(seqs) <- seqs
alignment <- AlignSeqs(DNAStringSet(seqs), anchor=NA, verbose = F)
phang.align <- phyDat(as(alignment, "matrix"), type="DNA")
write.phyDat(phang.align, file="alignment.fasta", format="fasta")
# Constructing the tree using FastTree:
system("./FastTreeMP -gtr -nt alignment.fasta  > gene-tree_all.tre", ignore.stderr = T)
# Importing the tree
fitGTR <- read.tree(file = "gene-tree_all.tre")
tree = phy_tree(fitGTR)
taxa_names(tree) <- sub(">", "", asv_headers)

# Creating a phyloseq object:
ps<- phyloseq(count_phy,sample_table_phy,tax_tab_phy,tree)
ps

# Plotting the library size:
df <- as.data.frame(sample_data(ps))
df$LibrarySize <- sample_sums(ps)
df <- df[order(df$LibrarySize),]
df$Index <- seq(nrow(df))
ggplot(data=df, aes(x=Index, y=LibrarySize, color=Sample)) + geom_point()
```

```{r clean3, message=FALSE, warning=FALSE, cache=FALSE, include=FALSE}
gc()
```
## **Removing contaminant ASVs:**

```{r decontamination, echo=T, message=FALSE, warning=FALSE, fig.dim= c(12,8), fig.align= "centre", layout="l-body-outset"}
sample_data(ps)$is.neg <- sample_data(ps)$Sample == "control"
contamdf.prev <- isContaminant(ps, method="prevalence", neg="is.neg")
table(contamdf.prev$contaminant) 
# threshold=0.5, will identify as contaminants all those ASVs which are more prevalent in negative controls than in the samples.
contamdf.prev05 <- isContaminant(ps, method="prevalence", neg="is.neg", threshold=0.5)
table(contamdf.prev05$contaminant)
contaminants <- contamdf.prev05[contamdf.prev05$contaminant == TRUE,]
contaminants_taxa <- tax_table(ps)[rownames(contaminants),]
###################
ps.pa <- transform_sample_counts(ps, function(abund) 1*(abund>0))
ps.pa.neg <- prune_samples(sample_data(ps.pa)$Sample == "control", ps.pa)
ps.pa.pos <- prune_samples(sample_data(ps.pa)$Sample == "Sample", ps.pa)
# Dataframe of prevalence in positive and negative samples:
df.pa <- data.frame(pa.pos=taxa_sums(ps.pa.pos), pa.neg=taxa_sums(ps.pa.neg),
                    contaminant=contamdf.prev05$contaminant)
# Plot showing the number of these taxa observed in negative controls and positive samples:
ggplot(data=df.pa, aes(x=pa.neg, y=pa.pos, color=contaminant)) + geom_point() +
  xlab("Number of Negative Controls") + ylab("Number of True Samples") + theme_bw() + 
  labs(color='Contaminants') +
  theme(panel.grid.major = element_blank(), legend.position = c(0.9,0.1),
        legend.background = element_rect(fill=alpha('white', 0)))  + 
  scale_x_continuous(breaks = seq(0, 8, by = 1)) +
  scale_y_continuous(breaks = seq(0, 80, by = 10))+
  scale_fill_viridis_d()

# Removing the contaminations
ps
ps.noncontam <- prune_taxa(!contamdf.prev05$contaminant, ps)
# Removing the mock community
ps.noncontam <- prune_samples(sample_names(ps.noncontam) != "I21726-L1", ps.noncontam) 
ps.noncontam <- prune_samples(sample_names(ps.noncontam) != "I21743-L1", ps.noncontam)
# Removing the controls out
ps.noncontam <- prune_samples(sample_data(ps.noncontam)$Sample == "Sample", ps.noncontam) 
ps.noncontam
# Number of features for each phyla
table(tax_table(ps.noncontam)[, "Phylum"], exclude = NULL)
unrecognised_phyla <- subset_taxa(ps.noncontam, is.na(Phylum) | Phylum %in% c("", "uncharacterized"))
ps.noncontam <- subset_taxa(ps.noncontam, !is.na(Phylum) & !Phylum %in% c("", "uncharacterized"))
# Compute prevalence of each feature:
prevdf = apply(X = otu_table(ps),MARGIN = ifelse(taxa_are_rows(ps), yes = 1, no = 2),
               FUN = function(x){sum(x > 0)})
prevdf = apply(X = otu_table(ps.noncontam),
               MARGIN = ifelse(taxa_are_rows(ps.noncontam), yes = 1, no = 2),
               FUN = function(x){sum(x > 0)})
prevdf = data.frame(Prevalence = prevdf,TotalAbundance = taxa_sums(ps.noncontam),tax_table(ps.noncontam))
# Mean and total prevelance of each feature:
phyla_prevelance <- plyr::ddply(prevdf, "Phylum", 
                                function(df1){cbind(mean(df1$Prevalence),sum(df1$Prevalence))})
colnames(phyla_prevelance) <- c("Phylum", "Mean Prevelance", "Total Prevelance(Sum of Prevelance)")
# Phyla Prevelence:
paged_table(phyla_prevelance)

# Plotting abundance before filtering
ggplot(prevdf, aes(TotalAbundance, Prevalence / nsamples(ps.noncontam),color=Phylum)) +
  geom_hline(yintercept = 0.05, alpha = 0.5, linetype = 2) + geom_point(size = 0.5, alpha = 0.7) +
  scale_x_log10() + xlab("Total Abundance") + ylab("Prevalence [Frac. Samples]") +
  facet_wrap(~Phylum) + theme(legend.position="none",
                              strip.background = element_rect(colour="black",fill="white"),
                              strip.text.x = element_text(margin = margin(0.05,0,0.05,0, "cm")),
                              text = element_text(size = 6),
                              axis.text = element_text(size = 4.5),
                              panel.background = element_rect(fill = "transparent"),
                              panel.grid.minor = element_line(color = "lightgray"),
                              panel.border = element_rect(fill = "transparent",
                                                          color = "black"))+
  scale_fill_viridis_d()

# Defining phylas to filter:
filterPhyla = c("Cyanobacteria")
# Filter entries with unidentified Phylum.
cyano_phyla <- subset_taxa(ps.noncontam, Phylum %in% filterPhyla)
ps1 = subset_taxa(ps.noncontam, !Phylum %in% filterPhyla)
# Exporting contaminant and unassigned asvs:
write.table(contaminants_taxa,file = "contaminants/contaminants_prev0.5_phyla.csv", sep = "\t")
write.table(tax_table(unrecognised_phyla),file = "contaminants/unrecognised_phyla.csv", sep = "\t")
write.table(tax_table(cyano_phyla),file = "contaminants/cyano_phyla.csv", sep = "\t")

# Exporting files for MicrobiomeAnalyst analysis:
write.tree(phy = phy_tree(ps1), file = "microbiomeanalyst/genetree_filtered_all.tre", tree.names = TRUE)
write.table(tax_table(ps1),file = "microbiomeanalyst/ASVs_taxonomy_filtered.csv", sep = "\t")
write.table(otu_table(ps1),file = "microbiomeanalyst/ASVs_counts_filtered.csv", sep = "\t")
write.table(sample_data(ps1),file = "microbiomeanalyst/Data_table_filtered.csv", sep = "\t")
```
```{r clean4, message=FALSE, warning=FALSE, cache=FALSE, include=FALSE}
rm(list = ls())
gc(full = TRUE)
```


## Session Info:
```{r info, echo=T, message=T, warning=T, fig.dim= c(12,8), fig.align= "centre", layout="l-body-outset"}
sessionInfo()

```



